Confusion Matrix:
[[3 2]
 [0 5]]

Classification Report:
              precision    recall  f1-score   support

        FAKE       1.00      0.60      0.75         5
        REAL       0.71      1.00      0.83         5

    accuracy                           0.80        10
   macro avg       0.86      0.80      0.79        10
weighted avg       0.86      0.80      0.79        10
